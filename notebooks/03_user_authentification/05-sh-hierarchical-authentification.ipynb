{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hierarchical User Authentication System Demo\n",
    "\n",
    "This notebook demonstrates a hierarchical approach to user authentication using behavioral biometrics. The hierarchical approach scales better as the number of users increases by first clustering users into groups, then training user-specific models within each cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Import Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Import our hierarchical authenticator\n",
    "import sys  \n",
    "sys.path.insert(1, '../src/')\n",
    "from user_hierarchical_auth import HierarchicalUserAuthenticator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov_slow = pd.read_csv('../data/processed/movement_slow_stat_cleaned.csv').drop(columns=['Unnamed: 0']).fillna(0)\n",
    "mov_fast = pd.read_csv('../data/processed/movement_fast_stat_cleaned.csv').drop(columns=['Unnamed: 0']).fillna(0)\n",
    "traffic_slow = pd.read_csv('../data/processed/traffic_slow_stat_cleaned.csv', index_col=0).fillna(0)\n",
    "traffic_fast = pd.read_csv('../data/processed/traffic_fast_stat_cleaned.csv', index_col=0).fillna(0)\n",
    "\n",
    "print(f\"Movement (Slow): {mov_slow.shape[0]} samples, {mov_slow.shape[1]} features\")\n",
    "print(f\"Movement (Fast): {mov_fast.shape[0]} samples, {mov_fast.shape[1]} features\")\n",
    "print(f\"Number of unique users in slow game: {mov_slow['ID'].nunique()}\")\n",
    "print(f\"Number of unique users in fast game: {mov_fast['ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Initialize the Hierarchical Authenticator System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = HierarchicalUserAuthenticator(num_clusters=None)\n",
    "user_data, all_user_ids = authenticator.prepare_data(mov_slow, mov_fast, traffic_slow, traffic_fast)\n",
    "print(f\"Prepared data for {len(all_user_ids)} unique users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. Cluster Users Based on Behavioral Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = authenticator.cluster_users(game_type='slow', method='kmeans', visualize=True)\n",
    "fast_clusters = authenticator.cluster_users(game_type='fast', method='kmeans', visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6. Train Hierarchical Authentication Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_slow = authenticator.train_hierarchical_models(game_type='slow', test_size=0.2, balance_classes=True)\n",
    "metrics_fast = authenticator.train_hierarchical_models(game_type='fast', test_size=0.2, balance_classes=True)\n",
    "\n",
    "print(\"\\nPerformance Metrics Summary by Game Type:\")\n",
    "display(authenticator.performance_metrics.groupby(['Game_Type']).mean())\n",
    "\n",
    "print(\"\\nPerformance Metrics Summary by Cluster (Slow Game):\")\n",
    "display(authenticator.performance_metrics[authenticator.performance_metrics['Game_Type'] == 'Slow'].groupby(['Cluster_ID']).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7. Authentication System Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test authentication\n",
    "slow_results = authenticator.test_hierarchical_authentication(game_type='slow', num_samples=5)\n",
    "fast_results = authenticator.test_hierarchical_authentication(game_type='fast', num_samples=5)\n",
    "\n",
    "# Analyze results more deeply\n",
    "print(\"\\nSlow Game Authentication Results:\")\n",
    "print(slow_results['Result_Type'].value_counts())\n",
    "\n",
    "print(\"\\nFast Game Authentication Results:\")\n",
    "print(fast_results['Result_Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot result distribution by user cluster\n",
    "plt.figure(figsize=(14, 7))\n",
    "for game_type, results in [('Slow', slow_results), ('Fast', fast_results)]:\n",
    "    for i, result_type in enumerate(['True Positive', 'True Negative', 'False Positive', 'False Negative']):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        # Get claimed user IDs for this result type\n",
    "        user_ids = results[results['Result_Type'] == result_type]['Claimed_User_ID'].unique()\n",
    "        \n",
    "        # Count users in each cluster\n",
    "        cluster_counts = {}\n",
    "        for uid in user_ids:\n",
    "            cluster = authenticator.user_to_cluster[game_type.lower()].get(uid, -1)\n",
    "            cluster_counts[cluster] = cluster_counts.get(cluster, 0) + 1\n",
    "        \n",
    "        if cluster_counts:\n",
    "            clusters = list(cluster_counts.keys())\n",
    "            counts = [cluster_counts[c] for c in clusters]\n",
    "            plt.bar(clusters, counts, alpha=0.7, label=game_type)\n",
    "            \n",
    "        plt.title(f'{result_type} by Cluster')\n",
    "        plt.xlabel('Cluster ID')\n",
    "        plt.ylabel('Number of Users')\n",
    "        plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8. Visualize Authentication Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator.visualize_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9. Compare to Flat (Non-Hierarchical) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = authenticator.compare_to_flat_model(game_type='slow')\n",
    "avg_comparison = comparison.groupby('Model_Type')[['Accuracy', 'F1', 'FAR', 'FRR']].mean()\n",
    "display(avg_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison by number of users in cluster\n",
    "slow_metrics = authenticator.performance_metrics[authenticator.performance_metrics['Game_Type'] == 'Slow']\n",
    "cluster_sizes = {cid: info['size'] for cid, info in authenticator.clusters['slow'].items()}\n",
    "slow_metrics['Cluster_Size'] = slow_metrics['Cluster_ID'].map(cluster_sizes)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='Cluster_Size', y='F1', data=slow_metrics, alpha=0.7)\n",
    "plt.title('F1 Score vs Cluster Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x='Cluster_Size', y='FAR', data=slow_metrics, alpha=0.7)\n",
    "plt.title('False Acceptance Rate vs Cluster Size')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10. Evaluate Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalability = authenticator.evaluate_scalability(max_users=100, step=20)\n",
    "print(\"\\nScalability Results:\")\n",
    "display(scalability[['Num_Users', 'Num_Clusters', 'Train_Speedup', 'Auth_Speedup']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11. Security Threshold Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine how authentication threshold affects security\n",
    "thresholds = np.arange(0, 1.01, 0.05)\n",
    "threshold_results = pd.DataFrame(columns=['Threshold', 'TPR', 'FPR', 'TNR', 'FNR', 'Accuracy', 'F1', 'Game_Type'])\n",
    "\n",
    "for game_type, results in [('Slow', slow_results), ('Fast', fast_results)]:\n",
    "    for threshold in thresholds:\n",
    "        # Apply threshold\n",
    "        predicted_genuine = results['Confidence'] >= threshold\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = sum((results['Is_Genuine_Attempt'] == True) & (predicted_genuine == True))\n",
    "        tn = sum((results['Is_Genuine_Attempt'] == False) & (predicted_genuine == False))\n",
    "        fp = sum((results['Is_Genuine_Attempt'] == False) & (predicted_genuine == True))\n",
    "        fn = sum((results['Is_Genuine_Attempt'] == True) & (predicted_genuine == False))\n",
    "        \n",
    "        total = len(results)\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        accuracy = (tp + tn) / total\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        threshold_results = threshold_results.append({\n",
    "            'Threshold': threshold,\n",
    "            'TPR': tpr, \n",
    "            'FPR': fpr,\n",
    "            'TNR': tnr,\n",
    "            'FNR': fnr,\n",
    "            'Accuracy': accuracy,\n",
    "            'F1': f1,\n",
    "            'Game_Type': game_type\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Plot threshold analysis\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "for game_type in ['Slow', 'Fast']:\n",
    "    game_data = threshold_results[threshold_results['Game_Type'] == game_type]\n",
    "    plt.plot(game_data['Threshold'], game_data['Accuracy'], marker='o', label=f'{game_type} Game')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "for game_type in ['Slow', 'Fast']:\n",
    "    game_data = threshold_results[threshold_results['Game_Type'] == game_type]\n",
    "    plt.plot(game_data['Threshold'], game_data['F1'], marker='o', label=f'{game_type} Game')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "for game_type in ['Slow', 'Fast']:\n",
    "    game_data = threshold_results[threshold_results['Game_Type'] == game_type]\n",
    "    plt.plot(game_data['FPR'], game_data['TPR'], marker='o', label=f'{game_type} Game')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "for game_type in ['Slow', 'Fast']:\n",
    "    game_data = threshold_results[threshold_results['Game_Type'] == game_type]\n",
    "    plt.plot(game_data['Threshold'], game_data['TPR'], marker='o', label=f'{game_type} TPR')\n",
    "    plt.plot(game_data['Threshold'], game_data['FPR'], marker='s', label=f'{game_type} FPR')\n",
    "plt.xlabel('Confidence Threshold')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('TPR and FPR vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
